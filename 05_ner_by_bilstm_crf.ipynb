{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BiLSTM-CRF解决NER任务\n",
    "\n",
    "### 深度学习解决NLP监督任务  \n",
    "![jupyter](./imgs/dl_for_nlp.png)\n",
    "\n",
    "### BiLSTM-CRF网络结构  \n",
    "![jupyter](./imgs/bilstm_crf.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /var/folders/96/0jnny1gj02j8pgfvb9by368m0000gn/T/jieba.cache\n",
      "Loading model cost 0.637 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import util\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 构造数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "(10748, 1343)"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_file = './bio/train.bio'\n",
    "test_data_file = './bio/test.bio'\n",
    "\n",
    "# 读取bio格式数据\n",
    "raw_train_sentences = util.read_bio_data(train_data_file)\n",
    "test_sentences = util.read_bio_data(test_data_file)\n",
    "len(raw_train_sentences), len(test_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10048, 700)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 划分出验证集\n",
    "# 深度学习，划分验证集的大小和测试集差不多即可\n",
    "train_sentences, val_sentences = train_test_split(\n",
    "    raw_train_sentences, test_size=700, random_state=1234\n",
    ")\n",
    "len(train_sentences), len(val_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['彭', 'B-nr', 'B-name'],\n",
       " ['小', 'I-nr', 'I-name'],\n",
       " ['军', 'E-nr', 'I-name'],\n",
       " ['认', 'B-v', 'O'],\n",
       " ['为', 'E-v', 'O'],\n",
       " ['，', 'S-x', 'O'],\n",
       " ['国', 'B-s', 'O'],\n",
       " ['内', 'E-s', 'O'],\n",
       " ['银', 'B-n', 'O'],\n",
       " ['行', 'E-n', 'O']]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sentences[0][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bio标签到id的映射\n",
    "tag_2_id = {\n",
    "    'O': 0,\n",
    "    'B-address': 1,\n",
    "    'I-address': 2,\n",
    "    'B-book': 3,\n",
    "    'I-book': 4,\n",
    "    'B-company': 5,\n",
    "    'I-company': 6,\n",
    "    'B-game': 7,\n",
    "    'I-game': 8,\n",
    "    'B-government': 9,\n",
    "    'I-government': 10,\n",
    "    'B-movie': 11,\n",
    "    'I-movie': 12,\n",
    "    'B-name': 13,\n",
    "    'I-name': 14,\n",
    "    'B-organization': 15,\n",
    "    'I-organization': 16,\n",
    "    'B-position': 17,\n",
    "    'I-position': 18,\n",
    "    'B-scene': 19,\n",
    "    'I-scene': 20\n",
    "}\n",
    "\n",
    "# id到bio标签的映射\n",
    "id_2_tag = {v: k for k, v in tag_2_id.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将数据集以及标签id之间的映射序列化保存，供后续的模型使用\n",
    "dataset_save_path = './data/dataset.pkl'\n",
    "with open(dataset_save_path, 'wb') as f:\n",
    "    data = (train_sentences, val_sentences, test_sentences, tag_2_id, id_2_tag)\n",
    "    pickle.dump(data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10048, 700, 1343)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 如何读取序列化后的数据\n",
    "with open(dataset_save_path, 'rb') as f:\n",
    "    train_sentences, val_sentences, test_sentences, tag_2_id, id_2_tag = pickle.load(f)\n",
    "    \n",
    "len(train_sentences), len(val_sentences), len(test_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3586, 2116, ['<PAD>', '<UNK>', '朱', '穆', '素', '淹', '橘', '徊', '瞅', '妖'])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 将训练语料中的字取出来\n",
    "words = set()\n",
    "for sentence in train_sentences:\n",
    "    for word, _, _ in sentence:\n",
    "        words.add(word.lower())\n",
    "words = list(words)\n",
    "words.insert(0, '<UNK>')  # 先在0位置插入unk\n",
    "words.insert(0, '<PAD>')  # 再在0位置插入PAD\n",
    "# word映射为id，即tokenizer\n",
    "word_2_id = {word: index for index, word in enumerate(words)}\n",
    "\n",
    "len(words), word_2_id['中'], words[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 序列化保存word与id之间的映射关系\n",
    "save_path = './bilstm_crf/maps.pkl'\n",
    "with open(save_path, 'wb') as f:\n",
    "    data = (words, word_2_id)\n",
    "    pickle.dump(data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取word与id之间的映射关系\n",
    "save_path = './bilstm_crf/maps.pkl'\n",
    "with open(save_path, 'rb') as f:\n",
    "    words, word_2_id = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 准备TF数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SEQ_LEN = 50 # 最长序列长度\n",
    "BATCH_SIZE = 64  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 制作TF数据集\n",
    "def build_dataset(bio_sequences, word_2_id, tag_2_id, max_seq_len, batch_size, is_train):\n",
    "    text_seqs = []\n",
    "    tag_seqs = []\n",
    "    for seq in bio_sequences:\n",
    "        current_text_seq = []\n",
    "        current_tag_seq = []\n",
    "        for word, _, tag in seq:\n",
    "            # 不在训练词表中，则获取unk\n",
    "            current_text_seq.append(word_2_id.get(word, 1))\n",
    "            current_tag_seq.append(tag_2_id.get(tag, 0))\n",
    "        text_seqs.append(current_text_seq)\n",
    "        tag_seqs.append(current_tag_seq)\n",
    "    pad_text_seqs = tf.keras.preprocessing.sequence.pad_sequences(text_seqs, padding='post', maxlen=max_seq_len)\n",
    "    pad_tag_seqs = tf.keras.preprocessing.sequence.pad_sequences(tag_seqs, padding='post', maxlen=max_seq_len)\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((pad_text_seqs, pad_tag_seqs))\n",
    "    if is_train:\n",
    "        buffer_size = len(pad_tag_seqs)\n",
    "        dataset = dataset.shuffle(buffer_size).batch(batch_size, drop_remainder=True).prefetch(buffer_size)\n",
    "    else:\n",
    "        dataset = dataset.batch(batch_size, drop_remainder=False).prefetch(batch_size)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = build_dataset(train_sentences, word_2_id, tag_2_id, MAX_SEQ_LEN, BATCH_SIZE, is_train=True)\n",
    "val_dataset = build_dataset(val_sentences, word_2_id, tag_2_id, MAX_SEQ_LEN, BATCH_SIZE, is_train=False)\n",
    "test_dataset = build_dataset(test_sentences, word_2_id, tag_2_id, MAX_SEQ_LEN, BATCH_SIZE, is_train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "texts:  [[2918 3314 2605 2392 1965 1573 2116 3116 3456 2468  187 2089  141 2100\n",
      "  1203 2462 2899 1581   30 2070 1091  188  548 1888 2704 1353 1749 1729\n",
      "  3242 3508 2162 3021 2395  660 2899 1338 2933 3541    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]\n",
      " [2007 2936 2392 2116 3250  341 1176 2899 2311 2820 2795   83 2070 1681\n",
      "  2580  196 3335 2392  548 1888 2704  263 2936 2266 2915 1081  263 3366\n",
      "   827 3335 2899 3007 2400 2509 2116 1983 2070    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]]\n",
      "\n",
      "labels:  [[13 14 14  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  9 10\n",
      "  10 10  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  5  6  6  6  0  1  2  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0]]\n"
     ]
    }
   ],
   "source": [
    "for example, label in val_dataset.take(1):\n",
    "    print('texts: ', example.numpy()[:2])\n",
    "    print()\n",
    "    print('labels: ', label.numpy()[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 模型训练\n",
    "\n",
    "![jupyter](./imgs/bilstm_crf_all.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_addons as tf_ad\n",
    "\n",
    "\n",
    "class NerModel(tf.keras.Model):\n",
    "    def __init__(self, lstm_dim, embedding_size, vocab_size, label_size, dropout_rate=0.5):\n",
    "        super(NerModel, self).__init__()\n",
    "        self.lstm_dim = lstm_dim  # lstm维度\n",
    "        self.vocab_size = vocab_size  # word embedding词表大小\n",
    "        self.label_size = label_size  # 标签数量\n",
    "        self.dropout_rate = dropout_rate # dropout比例\n",
    "        # 定义embedding层\n",
    "        self.embedding = tf.keras.layers.Embedding(\n",
    "            vocab_size,\n",
    "            embedding_size,\n",
    "            embeddings_regularizer='l2',\n",
    "            # 用0做mask\n",
    "            mask_zero=True\n",
    "        )\n",
    "        # dropout层\n",
    "        self.dropout = tf.keras.layers.Dropout(self.dropout_rate)\n",
    "        # BiLSTM层\n",
    "        self.biLSTM = tf.keras.layers.Bidirectional(\n",
    "            tf.keras.layers.LSTM(\n",
    "                self.lstm_dim,\n",
    "                #不是拿最终的输出，是每个状态的输出都是需要取出来的\n",
    "                return_sequences=True,\n",
    "                activation='tanh',\n",
    "                activity_regularizer='l2',\n",
    "                dropout=self.dropout_rate\n",
    "            )\n",
    "        )\n",
    "        # 标签分类层，提取发射分数\n",
    "        self.dense = tf.keras.layers.Dense(\n",
    "            self.label_size, activation='relu', activity_regularizer='l2'\n",
    "        )\n",
    "        # 定义CRF转移矩阵，提取转移分数\n",
    "        self.transition_params = tf.Variable(\n",
    "            tf.random.uniform(shape=(self.label_size, self.label_size))\n",
    "        )\n",
    "\n",
    "    def call(self, text, labels=None, training=None):\n",
    "        # 获取原始文本的真实长度，即token id不为0的长度(之前做了padding)\n",
    "        text_lens = tf.math.reduce_sum(tf.cast(tf.math.not_equal(text, 0), dtype=tf.int32), axis=-1)\n",
    "        # embedding\n",
    "        inputs = self.embedding(text)\n",
    "        # dropout\n",
    "        X = self.dropout(inputs, training)\n",
    "        # bilstm特征抽取\n",
    "        X = self.biLSTM(X)\n",
    "        # 发射分数\n",
    "        logits = self.dense(X)\n",
    "        # 如果label不为空，可以算loss\n",
    "        if labels is not None:\n",
    "            # 将标签序列转化为tf tensor\n",
    "            label_sequences = tf.convert_to_tensor(labels, dtype=tf.int32)\n",
    "            # 使用tf_ad.text.crf_log_likelihood定义crf层，获取crf loss以及更新转移矩阵\n",
    "            log_likelihood, self.transition_params = tf_ad.text.crf_log_likelihood(\n",
    "                inputs=logits,\n",
    "                tag_indices=label_sequences,\n",
    "                sequence_lengths=text_lens,\n",
    "                transition_params=self.transition_params\n",
    "            )\n",
    "            # 返回发射分数，文本真实长度，crf loss\n",
    "            return logits, text_lens, log_likelihood\n",
    "        else:\n",
    "             # 返回发射分数，文本真实长度(还原真实文本用的)\n",
    "            return logits, text_lens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "LSTM_DIM = 512\n",
    "EMBEDDING_DIM = 128\n",
    "DROPOUT = 0.5\n",
    "LR = 2e-3\n",
    "\n",
    "vocab_size = len(words)\n",
    "label_size= len(tag_2_id)\n",
    "\n",
    "# 初始化bilstm crf模型\n",
    "model = NerModel(\n",
    "    LSTM_DIM,\n",
    "    EMBEDDING_DIM,\n",
    "    vocab_size,\n",
    "    label_size,\n",
    "    DROPOUT)\n",
    "\n",
    "# 定义优化器\n",
    "optimizer = tf.keras.optimizers.Adam(LR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![jupyter](./imgs/bilstm_crf_score.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义模型的check ponit\n",
    "output_dir = './bilstm_crf'\n",
    "ckpt = tf.train.Checkpoint(optimizer=optimizer, model=model)\n",
    "ckpt.restore(tf.train.latest_checkpoint(output_dir))\n",
    "ckpt_manager = tf.train.CheckpointManager(ckpt,\n",
    "                                          output_dir,\n",
    "                                          checkpoint_name='model.ckpt',\n",
    "                                          max_to_keep=3    # 最多保存3步\n",
    "                                         )\n",
    "\n",
    "# 定义一次batch计算过程\n",
    "def run_one_step(model, text_batch, labels_batch, training=True):\n",
    "    with tf.GradientTape() as tape:\n",
    "        # 取出模型前向运算的发射分数、文本真实长度、crf loss\n",
    "        logits, text_lens, log_likelihood = model(\n",
    "            text_batch, labels_batch, training\n",
    "        )\n",
    "        # 将batch的crf loss进行平均\n",
    "        loss = - tf.reduce_mean(log_likelihood)\n",
    "    if training:\n",
    "        # 如果是训练，需要通过优化器进行梯度的更新\n",
    "        gradients = tape.gradient(loss, model.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "    # 验证、测试阶段无需更新梯度\n",
    "    return loss, logits, text_lens\n",
    "\n",
    "\n",
    "# 定义模型预测\n",
    "def predict_result(model, dataset, id_2_tag):\n",
    "    # 初始化loss、预测标签、真实标签列表\n",
    "    losses, preds, trues = [], [], []\n",
    "    # 对dataset进行batch计算\n",
    "    for _, (text_batch, labels_batch) in enumerate(dataset):\n",
    "        # 进行一次前向计算，获取crf loss、发射分数、文本真实长度\n",
    "        loss, logits, text_lens = run_one_step(model, text_batch, labels_batch, False)\n",
    "        losses.append(loss)\n",
    "        for logit, text_len, labels in zip(logits, text_lens, labels_batch):\n",
    "            # 根据序列真实长度使用维特比解码出最优序列\n",
    "            viterbi_path, _ = tf_ad.text.viterbi_decode(logit[:text_len], model.transition_params)\n",
    "            # 将最优序列作为预测序列\n",
    "            preds.extend(viterbi_path)\n",
    "            # 还原真实的标签序列\n",
    "            trues.extend(labels.numpy()[: text_len])\n",
    "    # 将标签id还原为标签\n",
    "    true_bios = [id_2_tag[i] for i in trues] \n",
    "    predict_bios = [id_2_tag[i] for i in preds] \n",
    "    return true_bios, predict_bios, losses\n",
    "\n",
    "# 结果评价，主要用于训练过程中查看验证集结果\n",
    "def metrics(model, dataset, tags):\n",
    "    true_bios, predict_bios, losses = predict_result(model, dataset, tags)\n",
    "    f1_score = util.get_f1_score(true_bios, predict_bios)  # 基于实体的f1 score\n",
    "    avg_loss = sum(losses) / len(losses) # 平均的loss\n",
    "    return f1_score, avg_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, step 50, train_loss 41.4876708984375\n",
      "Epoch 0, step 100, train_loss 35.505340576171875\n",
      "Epoch 0, step 150, train_loss 28.315336227416992\n",
      "Epoch 1, step 200, train_loss 27.595495223999023\n",
      "Epoch 1, step 250, train_loss 21.613262176513672\n",
      "Epoch 1, step 300, train_loss 22.24992561340332\n",
      "Epoch 2, step 350, train_loss 18.592220306396484\n",
      "Epoch 2, step 400, train_loss 19.803665161132812\n",
      "Epoch 2, step 450, train_loss 15.14367961883545\n",
      "Epoch 3, step 500, train_loss 14.602776527404785\n",
      "Epoch 3, step 550, train_loss 12.497684478759766\n",
      "Epoch 3, step 600, train_loss 11.619424819946289\n",
      "Epoch 4, step 650, train_loss 9.96174430847168\n",
      "Epoch 4, step 700, train_loss 10.135090827941895\n",
      "Epoch 4, step 750, train_loss 8.222332954406738\n",
      "Epoch 5, step 800, train_loss 7.762351989746094\n",
      "Epoch 5, step 850, train_loss 10.15503215789795\n",
      "Epoch 5, step 900, train_loss 6.439980506896973\n",
      "Epoch 6, step 950, train_loss 8.371956825256348\n",
      "Validation Result: val_f1 0.4992232004142931, val_loss 8.056118965148926\n",
      "New best f1: 0.4992232004142931, model saved!\n",
      "Epoch 6, step 1000, train_loss 7.116950511932373\n",
      "Validation Result: val_f1 0.5004812319538018, val_loss 8.016719818115234\n",
      "New best f1: 0.5004812319538018, model saved!\n",
      "Epoch 6, step 1050, train_loss 7.454722881317139\n",
      "Validation Result: val_f1 0.49647532729103727, val_loss 7.6027679443359375\n",
      "Epoch 7, step 1100, train_loss 6.2569355964660645\n",
      "Validation Result: val_f1 0.5022332506203474, val_loss 7.444192886352539\n",
      "New best f1: 0.5022332506203474, model saved!\n",
      "Epoch 7, step 1150, train_loss 6.405793190002441\n",
      "Validation Result: val_f1 0.5164319248826291, val_loss 7.125320911407471\n",
      "New best f1: 0.5164319248826291, model saved!\n",
      "Epoch 7, step 1200, train_loss 6.555479049682617\n",
      "Validation Result: val_f1 0.5417066155321189, val_loss 7.192538261413574\n",
      "New best f1: 0.5417066155321189, model saved!\n",
      "Epoch 7, step 1250, train_loss 6.973310947418213\n",
      "Validation Result: val_f1 0.5290199809705043, val_loss 6.982100963592529\n",
      "Epoch 8, step 1300, train_loss 6.081255912780762\n",
      "Validation Result: val_f1 0.5286384976525822, val_loss 6.652598857879639\n",
      "Epoch 8, step 1350, train_loss 5.717246055603027\n",
      "Validation Result: val_f1 0.5517882025081282, val_loss 6.306847095489502\n",
      "New best f1: 0.5517882025081282, model saved!\n",
      "Epoch 8, step 1400, train_loss 4.98491907119751\n",
      "Validation Result: val_f1 0.5575396825396824, val_loss 5.901920795440674\n",
      "New best f1: 0.5575396825396824, model saved!\n",
      "Epoch 9, step 1450, train_loss 5.4969482421875\n",
      "Validation Result: val_f1 0.5475177304964538, val_loss 5.99064826965332\n",
      "Epoch 9, step 1500, train_loss 5.2054853439331055\n",
      "Validation Result: val_f1 0.553639846743295, val_loss 5.7470383644104\n",
      "Epoch 9, step 1550, train_loss 5.642198085784912\n",
      "Validation Result: val_f1 0.5374771480804389, val_loss 5.906363010406494\n",
      "Epoch 10, step 1600, train_loss 4.593649387359619\n",
      "Validation Result: val_f1 0.5611510791366907, val_loss 5.6101226806640625\n",
      "New best f1: 0.5611510791366907, model saved!\n",
      "Epoch 10, step 1650, train_loss 4.22877836227417\n",
      "Validation Result: val_f1 0.5654162854528819, val_loss 5.442596435546875\n",
      "New best f1: 0.5654162854528819, model saved!\n",
      "Epoch 10, step 1700, train_loss 4.644900798797607\n",
      "Validation Result: val_f1 0.5598108747044918, val_loss 5.4344563484191895\n",
      "Epoch 11, step 1750, train_loss 4.508626937866211\n",
      "Validation Result: val_f1 0.5776309579990562, val_loss 5.118198394775391\n",
      "New best f1: 0.5776309579990562, model saved!\n",
      "Epoch 11, step 1800, train_loss 4.071891784667969\n",
      "Validation Result: val_f1 0.5719661335841957, val_loss 5.157998561859131\n",
      "Epoch 11, step 1850, train_loss 4.644222259521484\n",
      "Validation Result: val_f1 0.5911949685534591, val_loss 5.096359729766846\n",
      "New best f1: 0.5911949685534591, model saved!\n",
      "Epoch 12, step 1900, train_loss 3.6951005458831787\n",
      "Validation Result: val_f1 0.5805834528933524, val_loss 5.0350260734558105\n",
      "Epoch 12, step 1950, train_loss 3.147801637649536\n",
      "Validation Result: val_f1 0.600650860065086, val_loss 4.849952220916748\n",
      "New best f1: 0.600650860065086, model saved!\n",
      "Epoch 12, step 2000, train_loss 4.074487686157227\n",
      "Validation Result: val_f1 0.6056782334384858, val_loss 5.023619174957275\n",
      "New best f1: 0.6056782334384858, model saved!\n",
      "Epoch 13, step 2050, train_loss 4.076608180999756\n",
      "Validation Result: val_f1 0.5828779599271403, val_loss 4.936496257781982\n",
      "Epoch 13, step 2100, train_loss 3.7767765522003174\n",
      "Validation Result: val_f1 0.5941765241128298, val_loss 4.84260368347168\n",
      "Epoch 13, step 2150, train_loss 4.203235149383545\n",
      "Validation Result: val_f1 0.5790960451977402, val_loss 4.824918746948242\n",
      "Epoch 14, step 2200, train_loss 3.801475763320923\n",
      "Validation Result: val_f1 0.5825797239409805, val_loss 4.783065319061279\n",
      "Epoch 14, step 2250, train_loss 3.7656991481781006\n",
      "Validation Result: val_f1 0.5889570552147239, val_loss 4.766726016998291\n",
      "Epoch 14, step 2300, train_loss 3.610250234603882\n",
      "Validation Result: val_f1 0.587308939323761, val_loss 4.788618087768555\n",
      "Epoch 14, step 2350, train_loss 3.926494836807251\n",
      "Validation Result: val_f1 0.6035829122645843, val_loss 4.633549690246582\n",
      "Epoch 15, step 2400, train_loss 2.7831127643585205\n",
      "Validation Result: val_f1 0.5963302752293578, val_loss 4.606685161590576\n",
      "Epoch 15, step 2450, train_loss 3.79248046875\n",
      "Validation Result: val_f1 0.6020273248126927, val_loss 4.825099945068359\n",
      "Epoch 15, step 2500, train_loss 2.8710579872131348\n",
      "Validation Result: val_f1 0.5948670944087994, val_loss 4.70875358581543\n",
      "Epoch 16, step 2550, train_loss 2.7435379028320312\n",
      "Validation Result: val_f1 0.599444958371878, val_loss 4.519980430603027\n",
      "Early stoped!\n",
      "Train finished\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 20  # 迭代次数\n",
    "best_f1 = 0.0  # 记录最优的f1 score\n",
    "step = 0 # 记录训练步数\n",
    "early_stop_step = 0 # 记录早停步数\n",
    "STOP_STEP = 10 # 设置早停等待步数\n",
    "\n",
    "# 实现early stopping的代码\n",
    "for epoch in range(EPOCHS):\n",
    "    for _, (text_batch, labels_batch) in enumerate(train_dataset):\n",
    "        step = step + 1\n",
    "        # 一次训练过程，只取出loss\n",
    "        loss, _, _ = run_one_step(model, text_batch, labels_batch, True)\n",
    "        # 每隔50步打印训练的中间结果\n",
    "        if step % 50 == 0:\n",
    "            print(f'Epoch {epoch}, step {step}, train_loss {loss}')\n",
    "            if epoch > 5:  # 从第5个epoch开始计算验证集结果\n",
    "                # 计算验证集的实体分类f1 score，以及loss\n",
    "                f1_score, avg_loss = metrics(model, val_dataset, id_2_tag)\n",
    "                print(f'Validation Result: val_f1 {f1_score}, val_loss {avg_loss}')\n",
    "                # 记录最优的f1 score\n",
    "                if f1_score > best_f1:\n",
    "                    best_f1 = f1_score\n",
    "                    ckpt_manager.save()  # 记录最优时模型的权重\n",
    "                    print(f'New best f1: {best_f1}, model saved!')\n",
    "                    early_stop_step = 0\n",
    "                else:\n",
    "                    early_stop_step += 1\n",
    "                # 连续一定步数最优f1不再变化，则早停\n",
    "                if early_stop_step > STOP_STEP:\n",
    "                    print('Early stoped!')\n",
    "                    break\n",
    "    if early_stop_step > STOP_STEP:\n",
    "        break\n",
    "\n",
    "print(\"Train finished\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 模型评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"ner_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        multiple                  459008    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            multiple                  0         \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional multiple                  2625536   \n",
      "_________________________________________________________________\n",
      "dense (Dense)                multiple                  21525     \n",
      "=================================================================\n",
      "Total params: 3,106,510\n",
      "Trainable params: 3,106,510\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 查看模型结构\n",
    "# 每一层参数和总参数相差441，sqrt(441) = 21，summary并没有展现转移矩阵的训练。\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "     B-address       0.55      0.55      0.55       273\n",
      "        B-game       0.67      0.81      0.73       226\n",
      "     I-address       0.62      0.70      0.66      1045\n",
      "     B-company       0.71      0.58      0.64       279\n",
      "B-organization       0.61      0.50      0.55       206\n",
      "       I-scene       0.64      0.47      0.54       458\n",
      "        I-book       0.77      0.69      0.73       715\n",
      "        B-name       0.72      0.67      0.69       352\n",
      "       B-scene       0.61      0.39      0.47       124\n",
      "       B-movie       0.63      0.48      0.54       101\n",
      "        B-book       0.70      0.63      0.66       121\n",
      "I-organization       0.63      0.52      0.57       688\n",
      "    I-position       0.71      0.60      0.65       610\n",
      "     I-company       0.66      0.62      0.64      1031\n",
      "  I-government       0.67      0.82      0.74       855\n",
      "       I-movie       0.66      0.59      0.62       580\n",
      "        I-game       0.70      0.82      0.75      1065\n",
      "    B-position       0.70      0.60      0.65       347\n",
      "        I-name       0.67      0.65      0.66       732\n",
      "  B-government       0.67      0.75      0.71       190\n",
      "\n",
      "     micro avg       0.67      0.65      0.66      9998\n",
      "     macro avg       0.67      0.62      0.64      9998\n",
      "  weighted avg       0.67      0.65      0.66      9998\n",
      "\n",
      "evaluate result: \n",
      "Tag\tPrecision\tRecall\tF1\n",
      "  position\t69.13\t59.37\t63.88\n",
      "      game\t64.21\t76.99\t70.02\n",
      "     movie\t61.84\t46.53\t53.11\n",
      "   company\t62.28\t50.90\t56.02\n",
      "organization\t58.33\t47.57\t52.41\n",
      "   address\t44.12\t43.96\t44.04\n",
      "government\t61.79\t68.95\t65.17\n",
      "      book\t69.44\t61.98\t65.50\n",
      "     scene\t58.23\t37.10\t45.32\n",
      "      name\t69.85\t64.49\t67.06\n",
      "     total\t62.15\t57.05\t59.49\n"
     ]
    }
   ],
   "source": [
    "# 使用训练集进行模型评估\n",
    "true_bios, predict_bios, _ = predict_result(model, test_dataset, id_2_tag)\n",
    "metric_result = util.measure_by_tags(true_bios, predict_bios)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>From\\To</th>\n",
       "      <th>O</th>\n",
       "      <th>B-address</th>\n",
       "      <th>I-address</th>\n",
       "      <th>B-book</th>\n",
       "      <th>I-book</th>\n",
       "      <th>B-company</th>\n",
       "      <th>I-company</th>\n",
       "      <th>B-game</th>\n",
       "      <th>I-game</th>\n",
       "      <th>...</th>\n",
       "      <th>B-movie</th>\n",
       "      <th>I-movie</th>\n",
       "      <th>B-name</th>\n",
       "      <th>I-name</th>\n",
       "      <th>B-organization</th>\n",
       "      <th>I-organization</th>\n",
       "      <th>B-position</th>\n",
       "      <th>I-position</th>\n",
       "      <th>B-scene</th>\n",
       "      <th>I-scene</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>O</td>\n",
       "      <td>1.54</td>\n",
       "      <td>0.62</td>\n",
       "      <td>-1.75</td>\n",
       "      <td>-0.39</td>\n",
       "      <td>-1.30</td>\n",
       "      <td>0.46</td>\n",
       "      <td>-1.60</td>\n",
       "      <td>1.01</td>\n",
       "      <td>-1.47</td>\n",
       "      <td>...</td>\n",
       "      <td>0.97</td>\n",
       "      <td>-1.35</td>\n",
       "      <td>0.57</td>\n",
       "      <td>-2.15</td>\n",
       "      <td>1.57</td>\n",
       "      <td>-2.36</td>\n",
       "      <td>0.65</td>\n",
       "      <td>-2.62</td>\n",
       "      <td>1.16</td>\n",
       "      <td>-1.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B-address</td>\n",
       "      <td>-1.30</td>\n",
       "      <td>-1.02</td>\n",
       "      <td>2.52</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-0.68</td>\n",
       "      <td>-0.72</td>\n",
       "      <td>-2.07</td>\n",
       "      <td>-0.31</td>\n",
       "      <td>-1.52</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.56</td>\n",
       "      <td>-1.25</td>\n",
       "      <td>-0.98</td>\n",
       "      <td>-1.38</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-1.60</td>\n",
       "      <td>-0.64</td>\n",
       "      <td>-1.08</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>-2.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I-address</td>\n",
       "      <td>-1.41</td>\n",
       "      <td>-1.92</td>\n",
       "      <td>2.14</td>\n",
       "      <td>-0.68</td>\n",
       "      <td>-1.68</td>\n",
       "      <td>-0.63</td>\n",
       "      <td>-2.51</td>\n",
       "      <td>-0.95</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.47</td>\n",
       "      <td>-1.49</td>\n",
       "      <td>-0.76</td>\n",
       "      <td>-2.06</td>\n",
       "      <td>-1.10</td>\n",
       "      <td>-2.40</td>\n",
       "      <td>-0.57</td>\n",
       "      <td>-2.22</td>\n",
       "      <td>-0.99</td>\n",
       "      <td>-2.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B-book</td>\n",
       "      <td>-1.12</td>\n",
       "      <td>-0.19</td>\n",
       "      <td>-0.73</td>\n",
       "      <td>-0.54</td>\n",
       "      <td>2.93</td>\n",
       "      <td>0.09</td>\n",
       "      <td>-0.92</td>\n",
       "      <td>-0.23</td>\n",
       "      <td>-1.61</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.34</td>\n",
       "      <td>-1.60</td>\n",
       "      <td>-0.60</td>\n",
       "      <td>-1.45</td>\n",
       "      <td>-0.24</td>\n",
       "      <td>-1.12</td>\n",
       "      <td>-0.75</td>\n",
       "      <td>-1.19</td>\n",
       "      <td>0.39</td>\n",
       "      <td>-0.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I-book</td>\n",
       "      <td>-1.05</td>\n",
       "      <td>-0.06</td>\n",
       "      <td>-1.33</td>\n",
       "      <td>-1.24</td>\n",
       "      <td>2.12</td>\n",
       "      <td>-0.63</td>\n",
       "      <td>-0.94</td>\n",
       "      <td>-0.61</td>\n",
       "      <td>-1.81</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.50</td>\n",
       "      <td>-2.10</td>\n",
       "      <td>-0.49</td>\n",
       "      <td>-1.54</td>\n",
       "      <td>-0.86</td>\n",
       "      <td>-2.04</td>\n",
       "      <td>-0.06</td>\n",
       "      <td>-1.26</td>\n",
       "      <td>-0.77</td>\n",
       "      <td>-0.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>B-company</td>\n",
       "      <td>-1.47</td>\n",
       "      <td>-0.12</td>\n",
       "      <td>-1.94</td>\n",
       "      <td>-0.21</td>\n",
       "      <td>-1.58</td>\n",
       "      <td>-0.81</td>\n",
       "      <td>2.46</td>\n",
       "      <td>-0.06</td>\n",
       "      <td>-1.22</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.42</td>\n",
       "      <td>-1.26</td>\n",
       "      <td>-0.07</td>\n",
       "      <td>-1.76</td>\n",
       "      <td>0.06</td>\n",
       "      <td>-1.76</td>\n",
       "      <td>-0.21</td>\n",
       "      <td>-1.57</td>\n",
       "      <td>-0.61</td>\n",
       "      <td>-1.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>I-company</td>\n",
       "      <td>-1.28</td>\n",
       "      <td>-0.06</td>\n",
       "      <td>-2.22</td>\n",
       "      <td>-0.76</td>\n",
       "      <td>-1.09</td>\n",
       "      <td>-2.24</td>\n",
       "      <td>2.37</td>\n",
       "      <td>0.20</td>\n",
       "      <td>-1.90</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.36</td>\n",
       "      <td>-1.48</td>\n",
       "      <td>-0.07</td>\n",
       "      <td>-1.34</td>\n",
       "      <td>0.12</td>\n",
       "      <td>-2.44</td>\n",
       "      <td>0.24</td>\n",
       "      <td>-1.85</td>\n",
       "      <td>-0.24</td>\n",
       "      <td>-1.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>B-game</td>\n",
       "      <td>-1.29</td>\n",
       "      <td>-0.35</td>\n",
       "      <td>-1.84</td>\n",
       "      <td>0.06</td>\n",
       "      <td>-1.03</td>\n",
       "      <td>0.16</td>\n",
       "      <td>-1.28</td>\n",
       "      <td>0.16</td>\n",
       "      <td>3.04</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.39</td>\n",
       "      <td>-2.27</td>\n",
       "      <td>-0.48</td>\n",
       "      <td>-1.36</td>\n",
       "      <td>-0.56</td>\n",
       "      <td>-2.28</td>\n",
       "      <td>-0.12</td>\n",
       "      <td>-0.59</td>\n",
       "      <td>-0.13</td>\n",
       "      <td>-1.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>I-game</td>\n",
       "      <td>-1.14</td>\n",
       "      <td>-0.79</td>\n",
       "      <td>-1.46</td>\n",
       "      <td>-0.67</td>\n",
       "      <td>-1.75</td>\n",
       "      <td>-0.19</td>\n",
       "      <td>-1.65</td>\n",
       "      <td>-1.44</td>\n",
       "      <td>1.64</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.97</td>\n",
       "      <td>-2.03</td>\n",
       "      <td>-0.55</td>\n",
       "      <td>-1.18</td>\n",
       "      <td>-0.10</td>\n",
       "      <td>-2.02</td>\n",
       "      <td>-0.05</td>\n",
       "      <td>-0.68</td>\n",
       "      <td>-0.05</td>\n",
       "      <td>-0.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>B-government</td>\n",
       "      <td>-1.63</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>-1.94</td>\n",
       "      <td>0.03</td>\n",
       "      <td>-0.67</td>\n",
       "      <td>-0.07</td>\n",
       "      <td>-1.37</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>-0.82</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.15</td>\n",
       "      <td>-1.48</td>\n",
       "      <td>0.11</td>\n",
       "      <td>-0.60</td>\n",
       "      <td>-0.20</td>\n",
       "      <td>-2.22</td>\n",
       "      <td>0.01</td>\n",
       "      <td>-1.68</td>\n",
       "      <td>0.19</td>\n",
       "      <td>-0.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>I-government</td>\n",
       "      <td>-1.33</td>\n",
       "      <td>-0.30</td>\n",
       "      <td>-1.63</td>\n",
       "      <td>-0.27</td>\n",
       "      <td>-0.64</td>\n",
       "      <td>-0.47</td>\n",
       "      <td>-1.22</td>\n",
       "      <td>-0.53</td>\n",
       "      <td>-1.54</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.66</td>\n",
       "      <td>-0.40</td>\n",
       "      <td>-0.45</td>\n",
       "      <td>-1.28</td>\n",
       "      <td>-0.58</td>\n",
       "      <td>-1.94</td>\n",
       "      <td>0.04</td>\n",
       "      <td>-2.25</td>\n",
       "      <td>-0.45</td>\n",
       "      <td>-0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>B-movie</td>\n",
       "      <td>-1.08</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-1.56</td>\n",
       "      <td>-0.16</td>\n",
       "      <td>-0.98</td>\n",
       "      <td>0.04</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>-0.08</td>\n",
       "      <td>-1.19</td>\n",
       "      <td>...</td>\n",
       "      <td>0.05</td>\n",
       "      <td>3.76</td>\n",
       "      <td>-0.15</td>\n",
       "      <td>-1.50</td>\n",
       "      <td>-0.57</td>\n",
       "      <td>-1.41</td>\n",
       "      <td>0.15</td>\n",
       "      <td>-0.76</td>\n",
       "      <td>0.31</td>\n",
       "      <td>-1.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>I-movie</td>\n",
       "      <td>-0.84</td>\n",
       "      <td>-0.68</td>\n",
       "      <td>-0.93</td>\n",
       "      <td>-0.42</td>\n",
       "      <td>-2.11</td>\n",
       "      <td>-0.47</td>\n",
       "      <td>-1.18</td>\n",
       "      <td>-0.79</td>\n",
       "      <td>-1.72</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.50</td>\n",
       "      <td>2.17</td>\n",
       "      <td>-0.58</td>\n",
       "      <td>-1.64</td>\n",
       "      <td>-0.58</td>\n",
       "      <td>-1.84</td>\n",
       "      <td>-0.72</td>\n",
       "      <td>-0.65</td>\n",
       "      <td>-0.10</td>\n",
       "      <td>-0.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>B-name</td>\n",
       "      <td>-1.39</td>\n",
       "      <td>-0.17</td>\n",
       "      <td>-1.99</td>\n",
       "      <td>-0.42</td>\n",
       "      <td>-1.10</td>\n",
       "      <td>-0.08</td>\n",
       "      <td>-1.28</td>\n",
       "      <td>-0.59</td>\n",
       "      <td>-1.32</td>\n",
       "      <td>...</td>\n",
       "      <td>0.05</td>\n",
       "      <td>-1.68</td>\n",
       "      <td>-1.53</td>\n",
       "      <td>2.83</td>\n",
       "      <td>-0.62</td>\n",
       "      <td>-2.18</td>\n",
       "      <td>-0.92</td>\n",
       "      <td>-1.47</td>\n",
       "      <td>-0.46</td>\n",
       "      <td>-1.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>I-name</td>\n",
       "      <td>-0.85</td>\n",
       "      <td>-0.39</td>\n",
       "      <td>-1.32</td>\n",
       "      <td>-0.17</td>\n",
       "      <td>-1.97</td>\n",
       "      <td>-0.51</td>\n",
       "      <td>-2.38</td>\n",
       "      <td>-0.22</td>\n",
       "      <td>-1.63</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.67</td>\n",
       "      <td>-1.36</td>\n",
       "      <td>-1.13</td>\n",
       "      <td>2.03</td>\n",
       "      <td>-0.55</td>\n",
       "      <td>-2.49</td>\n",
       "      <td>0.31</td>\n",
       "      <td>-1.74</td>\n",
       "      <td>-0.55</td>\n",
       "      <td>-2.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>B-organization</td>\n",
       "      <td>-0.66</td>\n",
       "      <td>0.16</td>\n",
       "      <td>-1.81</td>\n",
       "      <td>-0.14</td>\n",
       "      <td>-0.52</td>\n",
       "      <td>-0.34</td>\n",
       "      <td>-1.25</td>\n",
       "      <td>-0.19</td>\n",
       "      <td>-1.79</td>\n",
       "      <td>...</td>\n",
       "      <td>0.29</td>\n",
       "      <td>-1.67</td>\n",
       "      <td>-0.48</td>\n",
       "      <td>-1.65</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>3.32</td>\n",
       "      <td>-0.47</td>\n",
       "      <td>-1.01</td>\n",
       "      <td>0.08</td>\n",
       "      <td>-1.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>I-organization</td>\n",
       "      <td>-1.14</td>\n",
       "      <td>-0.11</td>\n",
       "      <td>-1.56</td>\n",
       "      <td>-0.33</td>\n",
       "      <td>-0.97</td>\n",
       "      <td>-0.76</td>\n",
       "      <td>-1.62</td>\n",
       "      <td>-0.23</td>\n",
       "      <td>-1.94</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.07</td>\n",
       "      <td>-1.22</td>\n",
       "      <td>-0.54</td>\n",
       "      <td>-1.39</td>\n",
       "      <td>-1.38</td>\n",
       "      <td>2.16</td>\n",
       "      <td>-0.17</td>\n",
       "      <td>-2.40</td>\n",
       "      <td>-0.94</td>\n",
       "      <td>-1.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>B-position</td>\n",
       "      <td>-1.45</td>\n",
       "      <td>-0.29</td>\n",
       "      <td>-1.69</td>\n",
       "      <td>-0.42</td>\n",
       "      <td>-1.48</td>\n",
       "      <td>-0.49</td>\n",
       "      <td>-1.72</td>\n",
       "      <td>-0.35</td>\n",
       "      <td>-1.26</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.58</td>\n",
       "      <td>-0.98</td>\n",
       "      <td>-0.99</td>\n",
       "      <td>-1.20</td>\n",
       "      <td>-0.53</td>\n",
       "      <td>-2.36</td>\n",
       "      <td>-2.32</td>\n",
       "      <td>2.17</td>\n",
       "      <td>-0.79</td>\n",
       "      <td>-1.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>I-position</td>\n",
       "      <td>-0.75</td>\n",
       "      <td>-0.13</td>\n",
       "      <td>-1.55</td>\n",
       "      <td>-0.44</td>\n",
       "      <td>-0.78</td>\n",
       "      <td>0.04</td>\n",
       "      <td>-1.83</td>\n",
       "      <td>-0.12</td>\n",
       "      <td>-0.89</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.13</td>\n",
       "      <td>-0.92</td>\n",
       "      <td>1.23</td>\n",
       "      <td>-2.00</td>\n",
       "      <td>-0.95</td>\n",
       "      <td>-2.50</td>\n",
       "      <td>-2.70</td>\n",
       "      <td>1.86</td>\n",
       "      <td>0.06</td>\n",
       "      <td>-0.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>B-scene</td>\n",
       "      <td>-1.07</td>\n",
       "      <td>-0.28</td>\n",
       "      <td>-1.81</td>\n",
       "      <td>-0.46</td>\n",
       "      <td>-0.79</td>\n",
       "      <td>-0.12</td>\n",
       "      <td>-0.45</td>\n",
       "      <td>-0.17</td>\n",
       "      <td>-1.08</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.42</td>\n",
       "      <td>-1.76</td>\n",
       "      <td>-0.16</td>\n",
       "      <td>-0.85</td>\n",
       "      <td>0.20</td>\n",
       "      <td>-1.84</td>\n",
       "      <td>-0.51</td>\n",
       "      <td>-0.94</td>\n",
       "      <td>-0.48</td>\n",
       "      <td>3.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>I-scene</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-0.54</td>\n",
       "      <td>-2.36</td>\n",
       "      <td>-0.46</td>\n",
       "      <td>-0.61</td>\n",
       "      <td>-0.43</td>\n",
       "      <td>-0.68</td>\n",
       "      <td>0.05</td>\n",
       "      <td>-0.66</td>\n",
       "      <td>...</td>\n",
       "      <td>0.02</td>\n",
       "      <td>-1.02</td>\n",
       "      <td>-0.27</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>0.14</td>\n",
       "      <td>-2.16</td>\n",
       "      <td>0.26</td>\n",
       "      <td>-1.45</td>\n",
       "      <td>-0.74</td>\n",
       "      <td>2.82</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           From\\To     O  B-address  I-address  B-book  I-book  B-company  \\\n",
       "0                O  1.54       0.62      -1.75   -0.39   -1.30       0.46   \n",
       "1        B-address -1.30      -1.02       2.52   -0.01   -0.68      -0.72   \n",
       "2        I-address -1.41      -1.92       2.14   -0.68   -1.68      -0.63   \n",
       "3           B-book -1.12      -0.19      -0.73   -0.54    2.93       0.09   \n",
       "4           I-book -1.05      -0.06      -1.33   -1.24    2.12      -0.63   \n",
       "5        B-company -1.47      -0.12      -1.94   -0.21   -1.58      -0.81   \n",
       "6        I-company -1.28      -0.06      -2.22   -0.76   -1.09      -2.24   \n",
       "7           B-game -1.29      -0.35      -1.84    0.06   -1.03       0.16   \n",
       "8           I-game -1.14      -0.79      -1.46   -0.67   -1.75      -0.19   \n",
       "9     B-government -1.63      -0.25      -1.94    0.03   -0.67      -0.07   \n",
       "10    I-government -1.33      -0.30      -1.63   -0.27   -0.64      -0.47   \n",
       "11         B-movie -1.08      -0.01      -1.56   -0.16   -0.98       0.04   \n",
       "12         I-movie -0.84      -0.68      -0.93   -0.42   -2.11      -0.47   \n",
       "13          B-name -1.39      -0.17      -1.99   -0.42   -1.10      -0.08   \n",
       "14          I-name -0.85      -0.39      -1.32   -0.17   -1.97      -0.51   \n",
       "15  B-organization -0.66       0.16      -1.81   -0.14   -0.52      -0.34   \n",
       "16  I-organization -1.14      -0.11      -1.56   -0.33   -0.97      -0.76   \n",
       "17      B-position -1.45      -0.29      -1.69   -0.42   -1.48      -0.49   \n",
       "18      I-position -0.75      -0.13      -1.55   -0.44   -0.78       0.04   \n",
       "19         B-scene -1.07      -0.28      -1.81   -0.46   -0.79      -0.12   \n",
       "20         I-scene -0.01      -0.54      -2.36   -0.46   -0.61      -0.43   \n",
       "\n",
       "    I-company  B-game  I-game  ...  B-movie  I-movie  B-name  I-name  \\\n",
       "0       -1.60    1.01   -1.47  ...     0.97    -1.35    0.57   -2.15   \n",
       "1       -2.07   -0.31   -1.52  ...    -0.56    -1.25   -0.98   -1.38   \n",
       "2       -2.51   -0.95   -1.00  ...    -0.47    -1.49   -0.76   -2.06   \n",
       "3       -0.92   -0.23   -1.61  ...    -0.34    -1.60   -0.60   -1.45   \n",
       "4       -0.94   -0.61   -1.81  ...    -0.50    -2.10   -0.49   -1.54   \n",
       "5        2.46   -0.06   -1.22  ...    -0.42    -1.26   -0.07   -1.76   \n",
       "6        2.37    0.20   -1.90  ...    -0.36    -1.48   -0.07   -1.34   \n",
       "7       -1.28    0.16    3.04  ...    -0.39    -2.27   -0.48   -1.36   \n",
       "8       -1.65   -1.44    1.64  ...    -0.97    -2.03   -0.55   -1.18   \n",
       "9       -1.37   -0.03   -0.82  ...    -0.15    -1.48    0.11   -0.60   \n",
       "10      -1.22   -0.53   -1.54  ...    -0.66    -0.40   -0.45   -1.28   \n",
       "11      -1.00   -0.08   -1.19  ...     0.05     3.76   -0.15   -1.50   \n",
       "12      -1.18   -0.79   -1.72  ...    -0.50     2.17   -0.58   -1.64   \n",
       "13      -1.28   -0.59   -1.32  ...     0.05    -1.68   -1.53    2.83   \n",
       "14      -2.38   -0.22   -1.63  ...    -0.67    -1.36   -1.13    2.03   \n",
       "15      -1.25   -0.19   -1.79  ...     0.29    -1.67   -0.48   -1.65   \n",
       "16      -1.62   -0.23   -1.94  ...    -0.07    -1.22   -0.54   -1.39   \n",
       "17      -1.72   -0.35   -1.26  ...    -0.58    -0.98   -0.99   -1.20   \n",
       "18      -1.83   -0.12   -0.89  ...    -0.13    -0.92    1.23   -2.00   \n",
       "19      -0.45   -0.17   -1.08  ...    -0.42    -1.76   -0.16   -0.85   \n",
       "20      -0.68    0.05   -0.66  ...     0.02    -1.02   -0.27   -1.00   \n",
       "\n",
       "    B-organization  I-organization  B-position  I-position  B-scene  I-scene  \n",
       "0             1.57           -2.36        0.65       -2.62     1.16    -1.98  \n",
       "1             0.00           -1.60       -0.64       -1.08    -1.00    -2.26  \n",
       "2            -1.10           -2.40       -0.57       -2.22    -0.99    -2.49  \n",
       "3            -0.24           -1.12       -0.75       -1.19     0.39    -0.52  \n",
       "4            -0.86           -2.04       -0.06       -1.26    -0.77    -0.93  \n",
       "5             0.06           -1.76       -0.21       -1.57    -0.61    -1.71  \n",
       "6             0.12           -2.44        0.24       -1.85    -0.24    -1.44  \n",
       "7            -0.56           -2.28       -0.12       -0.59    -0.13    -1.19  \n",
       "8            -0.10           -2.02       -0.05       -0.68    -0.05    -0.65  \n",
       "9            -0.20           -2.22        0.01       -1.68     0.19    -0.57  \n",
       "10           -0.58           -1.94        0.04       -2.25    -0.45    -0.75  \n",
       "11           -0.57           -1.41        0.15       -0.76     0.31    -1.17  \n",
       "12           -0.58           -1.84       -0.72       -0.65    -0.10    -0.68  \n",
       "13           -0.62           -2.18       -0.92       -1.47    -0.46    -1.21  \n",
       "14           -0.55           -2.49        0.31       -1.74    -0.55    -2.17  \n",
       "15           -0.03            3.32       -0.47       -1.01     0.08    -1.33  \n",
       "16           -1.38            2.16       -0.17       -2.40    -0.94    -1.60  \n",
       "17           -0.53           -2.36       -2.32        2.17    -0.79    -1.56  \n",
       "18           -0.95           -2.50       -2.70        1.86     0.06    -0.69  \n",
       "19            0.20           -1.84       -0.51       -0.94    -0.48     3.87  \n",
       "20            0.14           -2.16        0.26       -1.45    -0.74     2.82  \n",
       "\n",
       "[21 rows x 22 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 可视化模型训练出的转移矩阵\n",
    "\n",
    "import pandas as pd\n",
    "transitions = list(model.transition_params.numpy())\n",
    "\n",
    "data = []\n",
    "for i, trans_list in enumerate(transitions):\n",
    "    row = {'From\\To': id_2_tag[i]}\n",
    "    for j, trans_score in enumerate(trans_list):\n",
    "        row[id_2_tag[j]] = round(trans_score, 2)\n",
    "    data.append(row)\n",
    "    \n",
    "pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 模型预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7fa87086ac10>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 加载模型进行预测\n",
    "output_dir = './bilstm_crf'\n",
    "saved_model = NerModel(LSTM_DIM,\n",
    "                 EMBEDDING_DIM,\n",
    "                 vocab_size,\n",
    "                 label_size,\n",
    "                 DROPOUT)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(LR)\n",
    "\n",
    "# 从Checkpoint中还原模型权重\n",
    "ckpt = tf.train.Checkpoint(optimizer=optimizer, model=saved_model)\n",
    "ckpt.restore(tf.train.latest_checkpoint(output_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 571 2362 3051   90 3077 2116 3250 2761 1473 3170   29 1478 2859 3242\n",
      "  2382 1567 1514 1818 3541    0    0    0    0    0    0    0    0]\n",
      " [3273 1173  731 3273  823 1331  263 2116 3250 2761 1473 3250   40 1478\n",
      "  2859 3242 2382   67 1567  347 1480 3366 2116 3250  808 1288 3541]\n",
      " [2287 1138 3324 3383 2416 1240 3366 1479  823 1452 1768  823 2288 1171\n",
      "  3541    0    0    0    0    0    0    0    0    0    0    0    0]]\n"
     ]
    }
   ],
   "source": [
    "# 在线预测\n",
    "test_sentences = ['李正茂出任中国电信集团有限公司总经理。',\n",
    "                 '2012年成立中国电信国际有限公司,总部设于中国香港。',\n",
    "                 '《长津湖》将于今年下半年上映。']\n",
    "tokenizer_sentences = []\n",
    "# 进行tokenizer\n",
    "for sentence in test_sentences:\n",
    "    tokenizer_sentences.append(\n",
    "        [word_2_id.get(word.lower(), 0) for word in sentence]\n",
    "    )\n",
    "# padding\n",
    "dataset = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "    tokenizer_sentences, padding='post'\n",
    ")\n",
    "print(dataset)\n",
    "\n",
    "# 使用模型进行预测\n",
    "logits, text_lens = saved_model.predict(dataset)\n",
    "paths = []\n",
    "for logit, text_len in zip(logits, text_lens):\n",
    "    # 维特比解码出最优序列\n",
    "    viterbi_path, _ = tf_ad.text.viterbi_decode(logit[:text_len], saved_model.transition_params)\n",
    "    paths.append(viterbi_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "李正茂出任中国电信集团有限公司总经理。\n",
      "['B-name', 'I-name', 'I-name', 'O', 'O', 'B-company', 'I-company', 'I-company', 'I-company', 'I-company', 'I-company', 'I-company', 'I-company', 'I-company', 'I-company', 'B-position', 'I-position', 'I-position', 'O']\n",
      "[\n",
      "    {\n",
      "        \"begin\": 0,\n",
      "        \"end\": 3,\n",
      "        \"tag\": \"name\",\n",
      "        \"word\": \"李正茂\"\n",
      "    },\n",
      "    {\n",
      "        \"begin\": 5,\n",
      "        \"end\": 15,\n",
      "        \"tag\": \"company\",\n",
      "        \"word\": \"中国电信集团有限公司\"\n",
      "    },\n",
      "    {\n",
      "        \"begin\": 15,\n",
      "        \"end\": 18,\n",
      "        \"tag\": \"position\",\n",
      "        \"word\": \"总经理\"\n",
      "    }\n",
      "]\n",
      "2012年成立中国电信国际有限公司,总部设于中国香港。\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'B-company', 'I-company', 'I-company', 'I-company', 'I-company', 'I-company', 'I-company', 'I-company', 'I-company', 'I-company', 'I-company', 'O', 'O', 'O', 'O', 'O', 'B-address', 'I-address', 'I-address', 'I-address', 'O']\n",
      "[\n",
      "    {\n",
      "        \"begin\": 6,\n",
      "        \"end\": 17,\n",
      "        \"tag\": \"company\",\n",
      "        \"word\": \"立中国电信国际有限公司\"\n",
      "    },\n",
      "    {\n",
      "        \"begin\": 22,\n",
      "        \"end\": 26,\n",
      "        \"tag\": \"address\",\n",
      "        \"word\": \"中国香港\"\n",
      "    }\n",
      "]\n",
      "《长津湖》将于今年下半年上映。\n",
      "['B-movie', 'I-movie', 'I-movie', 'I-movie', 'I-movie', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "[\n",
      "    {\n",
      "        \"begin\": 0,\n",
      "        \"end\": 5,\n",
      "        \"tag\": \"movie\",\n",
      "        \"word\": \"《长津湖》\"\n",
      "    }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "# 结果展示\n",
    "for text, path in zip(test_sentences, paths):\n",
    "    print(text)\n",
    "    bio_seq = [id_2_tag[tag_id] for tag_id in path]\n",
    "    print(bio_seq)\n",
    "    entities_result = util.bio_2_entities(bio_seq)\n",
    "    json_result = util.formatting_result(entities_result, text)\n",
    "    print(json_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pycharm-b35e09b3",
   "language": "python",
   "display_name": "PyCharm (Chapter.4)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}