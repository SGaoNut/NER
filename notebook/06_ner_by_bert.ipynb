{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERT解决NER任务\n",
    "\n",
    "![jupyter](./imgs/bert_ner.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /tmp/jieba.cache\n",
      "Loading model cost 0.720 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "# transformer封装了很多Bert\n",
    "from transformers import BertTokenizer, TFBertForTokenClassification\n",
    "\n",
    "import util\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 构建数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10048, 700, 1343)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_save_path = './data/dataset.pkl'\n",
    "\n",
    "with open(dataset_save_path, 'rb') as f:\n",
    "    train_sentences, val_sentences, test_sentences, tag_2_id, id_2_tag = pickle.load(f)\n",
    "\n",
    "len(train_sentences), len(val_sentences), len(test_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'O': 0,\n",
       " 'B-address': 1,\n",
       " 'I-address': 2,\n",
       " 'B-book': 3,\n",
       " 'I-book': 4,\n",
       " 'B-company': 5,\n",
       " 'I-company': 6,\n",
       " 'B-game': 7,\n",
       " 'I-game': 8,\n",
       " 'B-government': 9,\n",
       " 'I-government': 10,\n",
       " 'B-movie': 11,\n",
       " 'I-movie': 12,\n",
       " 'B-name': 13,\n",
       " 'I-name': 14,\n",
       " 'B-organization': 15,\n",
       " 'I-organization': 16,\n",
       " 'B-position': 17,\n",
       " 'I-position': 18,\n",
       " 'B-scene': 19,\n",
       " 'I-scene': 20}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag_2_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids\n",
      "[101, 3330, 3633, 5744, 1139, 818, 704, 1744, 4510, 928, 7415, 1730, 3300, 7361, 1062, 1385, 2600, 5307, 4415, 511, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "token_type_ids\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "attention_mask\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-chinese')\n",
    "\n",
    "test_sentence = '李正茂出任中国电信集团有限公司总经理。'\n",
    "\n",
    "bert_input = tokenizer.encode_plus(\n",
    "    test_sentence,\n",
    "    add_special_tokens=True,\n",
    "    max_length=50,\n",
    "    pad_to_max_length=True,\n",
    "    truncation=True,\n",
    "    return_attention_mask=True,\n",
    ")\n",
    "\n",
    "for k, v in bert_input.items():\n",
    "    print(k)\n",
    "    print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_sample_to_feature(text, max_length):\n",
    "    return tokenizer.encode_plus(\n",
    "        text,\n",
    "        add_special_tokens=True,\n",
    "        max_length=max_length,\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        return_attention_mask=True,\n",
    "    )\n",
    "\n",
    "\n",
    "def map_sample_to_dict(input_ids, token_type_ids, attention_masks, label):\n",
    "    return {\n",
    "               \"input_ids\": input_ids,\n",
    "               \"token_type_ids\": token_type_ids,\n",
    "               \"attention_mask\": attention_masks,\n",
    "           }, label\n",
    "\n",
    "\n",
    "def build_dataset(samples, tag_2_id, max_length, batch_size, is_train):\n",
    "    input_ids_list = []\n",
    "    token_type_ids_list = []\n",
    "    attention_mask_list = []\n",
    "    label_list = []\n",
    "\n",
    "    for sample in samples:\n",
    "        text = [x[0] for x in sample]\n",
    "        label = [tag_2_id.get(x[2], 0) for x in sample][: max_length - 1]\n",
    "        # 开头加PAD，即CLS\n",
    "        label.insert(0, 0)\n",
    "        bert_input = convert_sample_to_feature(text, max_length)\n",
    "        input_ids_list.append(bert_input['input_ids'])\n",
    "        token_type_ids_list.append(bert_input['token_type_ids'])\n",
    "        attention_mask_list.append(bert_input['attention_mask'])\n",
    "        label_list.append(label)\n",
    "    label_list = pad_sequences(label_list, padding='post', maxlen=max_length, )\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(\n",
    "        (input_ids_list, attention_mask_list, token_type_ids_list, label_list)\n",
    "    )\n",
    "    dataset = dataset.map(map_sample_to_dict)\n",
    "    buffer_size = len(label_list)\n",
    "    if is_train:\n",
    "        dataset = dataset.shuffle(buffer_size)\n",
    "    dataset = dataset.batch(batch_size).prefetch(buffer_size)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16\n",
    "MAX_SEQ_LEN = 52\n",
    "\n",
    "# dataset\n",
    "train_dataset = build_dataset(train_sentences, tag_2_id, MAX_SEQ_LEN, BATCH_SIZE, True)\n",
    "val_dataset = build_dataset(val_sentences, tag_2_id, MAX_SEQ_LEN, BATCH_SIZE, False)\n",
    "test_dataset = build_dataset(test_sentences, tag_2_id, MAX_SEQ_LEN, BATCH_SIZE, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 模型训练\n",
    "\n",
    "![jupyter](./imgs/bert_token_classification.jpeg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_LABELS = len(list(tag_2_id))\n",
    "LR = 1e-5\n",
    "EPOCHS = 10\n",
    "PATIENCE = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBertForTokenClassification.\n",
      "\n",
      "Some weights or buffers of the TF 2.0 model TFBertForTokenClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# 模型初始化\n",
    "model = TFBertForTokenClassification.from_pretrained(\n",
    "    'bert-base-chinese',\n",
    "    from_pt=True,\n",
    "    num_labels=NUM_LABELS\n",
    ")\n",
    "# 定义优化器\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=LR)\n",
    "\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "metric = tf.keras.metrics.SparseCategoricalAccuracy('accuracy')\n",
    "model.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss=loss,\n",
    "    metrics=[metric]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method Socket.send of <zmq.Socket(zmq.PUSH) at 0x7f596305b940>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method Socket.send of <zmq.Socket(zmq.PUSH) at 0x7f596305b940>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "628/628 [==============================] - ETA: 0s - loss: 0.3648 - accuracy: 0.9000WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "628/628 [==============================] - 109s 174ms/step - loss: 0.3648 - accuracy: 0.9000 - val_loss: 0.2082 - val_accuracy: 0.9325\n",
      "Epoch 2/10\n",
      "628/628 [==============================] - 110s 175ms/step - loss: 0.1670 - accuracy: 0.9441 - val_loss: 0.1857 - val_accuracy: 0.9400\n",
      "Epoch 3/10\n",
      "628/628 [==============================] - 109s 174ms/step - loss: 0.1297 - accuracy: 0.9566 - val_loss: 0.1797 - val_accuracy: 0.9443\n",
      "Epoch 4/10\n",
      "628/628 [==============================] - 109s 174ms/step - loss: 0.1052 - accuracy: 0.9645 - val_loss: 0.1762 - val_accuracy: 0.9452\n",
      "Epoch 5/10\n",
      "628/628 [==============================] - 109s 174ms/step - loss: 0.0841 - accuracy: 0.9719 - val_loss: 0.1896 - val_accuracy: 0.9451\n",
      "Epoch 6/10\n",
      "628/628 [==============================] - 110s 174ms/step - loss: 0.0676 - accuracy: 0.9779 - val_loss: 0.2015 - val_accuracy: 0.9479\n",
      "Epoch 7/10\n",
      "628/628 [==============================] - 109s 174ms/step - loss: 0.0543 - accuracy: 0.9823 - val_loss: 0.2155 - val_accuracy: 0.9465\n",
      "Epoch 8/10\n",
      "628/628 [==============================] - 109s 174ms/step - loss: 0.0428 - accuracy: 0.9862 - val_loss: 0.2280 - val_accuracy: 0.9452\n"
     ]
    }
   ],
   "source": [
    "callback = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_accuracy',\n",
    "    patience=PATIENCE,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "# 模型训练\n",
    "bert_history = model.fit(\n",
    "    train_dataset,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=[callback],\n",
    "    validation_data=val_dataset\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "WARNING:tensorflow:From /home/teacher/.local/lib/python3.8/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "WARNING:tensorflow:From /home/teacher/.local/lib/python3.8/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "INFO:tensorflow:Assets written to: ./bert/bert_ner/saved_model/1/assets\n"
     ]
    }
   ],
   "source": [
    "# 保存模型\n",
    "save_model_path = \"./bert/bert_ner\"\n",
    "model.save_pretrained(save_model_path, saved_model=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 模型评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "        B-name       0.85      0.89      0.87       352\n",
      "  I-government       0.77      0.84      0.80       855\n",
      "        B-game       0.81      0.79      0.80       226\n",
      "        I-book       0.92      0.82      0.87       715\n",
      "        I-name       0.83      0.89      0.86       732\n",
      "        B-book       0.88      0.81      0.84       121\n",
      "       B-movie       0.80      0.80      0.80       101\n",
      "       I-scene       0.69      0.73      0.71       458\n",
      "       B-scene       0.62      0.64      0.63       124\n",
      "     I-address       0.77      0.73      0.75      1045\n",
      "        I-game       0.83      0.79      0.81      1065\n",
      "    I-position       0.79      0.77      0.78       610\n",
      "    B-position       0.77      0.75      0.76       347\n",
      "     B-address       0.68      0.64      0.66       273\n",
      "  B-government       0.77      0.81      0.78       190\n",
      "I-organization       0.71      0.60      0.65       688\n",
      "     I-company       0.72      0.81      0.76      1031\n",
      "     B-company       0.77      0.83      0.80       279\n",
      "B-organization       0.75      0.67      0.71       206\n",
      "       I-movie       0.78      0.90      0.83       580\n",
      "\n",
      "     micro avg       0.78      0.78      0.78      9998\n",
      "     macro avg       0.77      0.77      0.77      9998\n",
      "  weighted avg       0.78      0.78      0.78      9998\n",
      "\n",
      "evaluate result: \n",
      "Tag\tPrecision\tRecall\tF1\n",
      "   company\t68.33\t73.48\t70.81\n",
      "      name\t82.11\t86.08\t84.05\n",
      "     scene\t58.59\t60.48\t59.52\n",
      "government\t70.50\t74.21\t72.31\n",
      "   address\t57.31\t54.58\t55.91\n",
      "      game\t71.36\t69.47\t70.40\n",
      "  position\t75.89\t73.49\t74.67\n",
      "organization\t70.65\t63.11\t66.67\n",
      "      book\t77.68\t71.90\t74.68\n",
      "     movie\t78.22\t78.22\t78.22\n",
      "     total\t71.54\t71.25\t71.39\n"
     ]
    }
   ],
   "source": [
    "output = model.predict(test_dataset)\n",
    "pred_logits = output.logits\n",
    "pred_label_ids = np.argmax(pred_logits, axis=2).tolist()\n",
    "\n",
    "preds, trues = [], []\n",
    "\n",
    "for sample, pred_ids in zip(test_sentences, pred_label_ids):\n",
    "    label = [x[2] for x in sample]\n",
    "    seq_len = len(label)  # 获取序列真实长度\n",
    "    pred_label = [id_2_tag[x] for x in pred_ids[1: seq_len + 1]]  # 开头0为CLS，所以从1开始取\n",
    "    assert len(label) == len(pred_label), (label, pred_label)\n",
    "    preds.extend(pred_label)\n",
    "    trues.extend(label)\n",
    "\n",
    "# 对结果进行评估\n",
    "metric_result = util.measure_by_tags(trues, preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 模型预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at ./bert/bert_ner were not used when initializing TFBertForTokenClassification: ['dropout_37']\n",
      "- This IS expected if you are initializing TFBertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFBertForTokenClassification were initialized from the model checkpoint at ./bert/bert_ner.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertForTokenClassification for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "# 加载模型\n",
    "save_model_path = \"./bert/bert_ner\"\n",
    "saved_model = TFBertForTokenClassification.from_pretrained(save_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用模型进行预测\n",
    "predict_sentences = ['李正茂出任中国电信集团有限公司总经理。',\n",
    "                     '2012年成立中国电信国际有限公司,总部设于中国香港。',\n",
    "                     '《长津湖》将于今年下半年上映。']\n",
    "\n",
    "# tokenizer\n",
    "predict_inputs = tokenizer(predict_sentences, padding=True, max_length=MAX_SEQ_LEN, return_tensors=\"tf\")\n",
    "# 模型前向运算\n",
    "output = saved_model(predict_inputs)\n",
    "# 获取标签分数\n",
    "predict_logits = output.logits.numpy()\n",
    "# 取最大标签分数结果\n",
    "predict_label_ids = np.argmax(predict_logits, axis=2).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "李正茂出任中国电信集团有限公司总经理。\n",
      "['B-name', 'I-name', 'I-name', 'O', 'O', 'B-company', 'I-company', 'I-company', 'I-company', 'I-company', 'I-company', 'I-company', 'I-company', 'I-company', 'I-company', 'B-position', 'I-position', 'I-position', 'O']\n",
      "[\n",
      "    {\n",
      "        \"begin\": 0,\n",
      "        \"end\": 3,\n",
      "        \"tag\": \"name\",\n",
      "        \"word\": \"李正茂\"\n",
      "    },\n",
      "    {\n",
      "        \"begin\": 5,\n",
      "        \"end\": 15,\n",
      "        \"tag\": \"company\",\n",
      "        \"word\": \"中国电信集团有限公司\"\n",
      "    },\n",
      "    {\n",
      "        \"begin\": 15,\n",
      "        \"end\": 18,\n",
      "        \"tag\": \"position\",\n",
      "        \"word\": \"总经理\"\n",
      "    }\n",
      "]\n",
      "2012年成立中国电信国际有限公司,总部设于中国香港。\n",
      "['O', 'O', 'O', 'O', 'B-company', 'I-company', 'I-company', 'I-company', 'I-company', 'I-company', 'I-company', 'I-company', 'I-company', 'I-company', 'O', 'O', 'O', 'O', 'O', 'B-address', 'I-address', 'I-address', 'I-address', 'O', 'O']\n",
      "[\n",
      "    {\n",
      "        \"begin\": 4,\n",
      "        \"end\": 14,\n",
      "        \"tag\": \"company\",\n",
      "        \"word\": \"年成立中国电信国际有\"\n",
      "    },\n",
      "    {\n",
      "        \"begin\": 19,\n",
      "        \"end\": 23,\n",
      "        \"tag\": \"address\",\n",
      "        \"word\": \"部设于中\"\n",
      "    }\n",
      "]\n",
      "《长津湖》将于今年下半年上映。\n",
      "['B-movie', 'I-movie', 'I-movie', 'I-movie', 'I-movie', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "[\n",
      "    {\n",
      "        \"begin\": 0,\n",
      "        \"end\": 5,\n",
      "        \"tag\": \"movie\",\n",
      "        \"word\": \"《长津湖》\"\n",
      "    }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "# 格式化展示结果\n",
    "for text, pred_ids in zip(predict_sentences, predict_label_ids):\n",
    "    print(text)\n",
    "    seq_len = len(text)\n",
    "    bio_seq = [id_2_tag[x] for x in pred_ids[1: seq_len + 1]]\n",
    "    print(bio_seq)\n",
    "    entities_result = util.bio_2_entities(bio_seq)\n",
    "    json_result = util.formatting_result(entities_result, text)\n",
    "    print(json_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}